## MNIST Classification with OOP

This project leverages the **MNIST** dataset to classify handwritten digits using three distinct approaches: **Random Forest, Feed-Forward Neural Network (NN), and Convolutional Neural Network (CNN)**. Each model is built with object-oriented programming (**OOP**) principles to ensure a modular, maintainable, and scalable codebase.

## ğŸ“‘Table of Contents
- ğŸ“–[Project Overview](#project-overview)
- ğŸ“Š[Dataset](#dataset)
- ğŸ“[Project Structure](#project-structure)
- ğŸ› ï¸[Installation](#installation)
- ğŸš€[Usage](#usage)
- ğŸ“[Files](#files)

## ğŸ“–Project Overview
In this project, I explore different **machine learning techniques for image classification**. The workflow begins with comprehensive data preprocessing of the MNIST dataset, followed by the implementation and evaluation of three models:

- **Random Forest:** An ensemble-based approach to improve prediction reliability.
- **Feed-Forward Neural Network (NN):** A simple neural architecture designed to capture complex patterns.
- **Convolutional Neural Network (CNN):** A deep learning model specifically tailored for image feature extraction.

By leveraging OOP, each model is encapsulated within its own class, making it easier to develop, test, and extend. This structured approach not only simplifies debugging and maintenance but also facilitates the integration of additional models and features in the future.
### ğŸ“ŠDataset

The MNIST dataset is used for training and testing the models. It consists of 60,000 training images and 10,000 testing
images of handwritten digits (0-9).

### ğŸ“Project Structure
``` task1/
   â”‚â”€â”€ classifiers/
   â”‚   â”œâ”€â”€ CNNClassifier.py              # CNN Model Implementation
   â”‚   â”œâ”€â”€ Feed_forward_nn_Classifier.py # Feed-Forward NN Model
   â”‚   â”œâ”€â”€ MnistClassifierInterface.py   # Interface for classifiers
   â”‚   â”œâ”€â”€ RFClassifier.py               # Random Forest Model
   â”‚   â”œâ”€â”€ MnistClassifier.py            # Base MNIST classifier class
   â”‚â”€â”€ demo.ipynb                        # Jupyter notebook for testing models
   â”‚â”€â”€ README.md                         # Project documentation
   â”‚â”€â”€ requirements.txt                   # Required dependencies
```

### ğŸ› ï¸Installation

1. Clone the repository:
    ```sh
    git clone <repository_url>
    cd <repository_directory>
    ```
2. Create a virtual environment :
    ```sh
    python -m venv venv
    source venv/bin/activate  # On Windows use: venv\Scripts\activate

3. Install the required packages:
    ```sh
    pip install -r requirements.txt
    ```
### ğŸš€Usage

1. **ğŸ¤–Training the Models**:
    - To train the Feed-Forward Neural Network:
        ```python
        from task1.classifiers.Feed_forward_nn_Classifier import FeedForwardNNClassifier

        classifier = FeedForwardNNClassifier()
        classifier.train(x_train, y_train)
        ```

    - To train the Random Forest classifier:
        ```python
        from task1.classifiers.RFClassifier import RFClassifier

        classifier = RFClassifier()
        classifier.train(x_train, y_train)
        ```

    - To train the Convolutional Neural Network:
        ```python
        from task1.classifiers.CNNClassifier import CNNClassifier

        classifier = CNNClassifier()
        classifier.train(x_train, y_train)
        ```

2. **âœ¨Making Predictions**:
    - To make predictions with the Feed-Forward Neural Network:
        ```python
        predictions = classifier.predict(x_test)
        ```

    - To make predictions with the Random Forest classifier:
        ```python
        predictions = classifier.predict(x_test)
        ```

    - To make predictions with the Convolutional Neural Network:
        ```python
        predictions = classifier.predict(x_test)
        ```

3. **ğŸ¤–Validating the Models**:
    - To validate the Feed-Forward Neural Network:
        ```python
        accuracy = classifier.validate(x_val, y_val)
        ```

    - To validate the Random Forest classifier:
        ```python
        metrics = classifier.validate(x_val, y_val)
        ```

    - To validate the Convolutional Neural Network:
        ```python
        accuracy = classifier.validate(x_val, y_val)
        ```

4. **ğŸ“ŠVisualizing Results**:
    - To visualize results for the Feed-Forward Neural Network:
        ```python
        classifier.visualize_results(x_test, y_test)
        ```

    - To visualize results for the Random Forest classifier:
        ```python
        classifier.visualize_results(x_test, y_test)
        ```

    - To visualize results for the Convolutional Neural Network:
        ```python
        classifier.visualize_results(x_test, y_test)
        ```

5. **ğŸŒUsing the Demo Notebook**:
    - Open the `demo.ipynb` notebook to see examples of how to train, predict, validate, and visualize results for all models. The notebook provides a step-by-step guide and visualizations for better understanding.

### ğŸ“Files
- **task1/classifiers/CNNClassifier.py:** Contains the implementation of the Convolutional Neural Network (CNN) classifier.
- **task1/classifiers/Feed_forward_nn_Classifier.py:** Contains the implementation of the Feed-Forward Neural Network (NN) classifier.
- **task1/classifiers/MnistClassifierInterface.py:** Defines the interface that all classifiers must implement.
- **task1/classifiers/RFClassifier.py:** Contains the implementation of the Random Forest classifier.
- **task1/classifiers/MnistClassifier.py:** Base class for MNIST classifiers.
- **task1/demo.ipynb:** Jupyter notebook for testing the models.
- **task1/README.md:** Project documentation.
- **task1/requirements.txt:** Lists the required dependencies for the project.

### ğŸŒEdge Cases
**1. Input Data Shape:**  
- Ensure correct input shape: flattened for Feed-Forward NN, 2D/3D for CNN.

**2. Missing/Corrupted Data:**  
- Ensure correct input shape: flattened for Feed-Forward NN, 2D/3D for CNN.

**3.Small Datasets:** 
- Ensure models perform well on small datasets.

**4. Class Imbalance:**
- Use techniques like oversampling, undersampling, or class weights.

**5. Large Batch Sizes or Memory Constraints**
- Be mindful of batch sizes if using GPU-accelerated training with large datasets.

### ğŸ¤ Contributing
Contributions are welcome! Please open an issue or submit a pull request for any improvements or bug fixes.